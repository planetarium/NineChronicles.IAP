import os
import csv
import argparse
from datetime import datetime, timezone
from dotenv import load_dotenv
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, Session
from common.models.product import Product, ProductRarity, ProductAssetUISize, ProductType
from sqlalchemy.exc import SQLAlchemyError

# âœ… .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# âœ… í™˜ê²½ ë³€ìˆ˜ì—ì„œ DB URL ê°€ì ¸ì˜¤ê¸°
DATABASE_URL = os.getenv("DATABASE_URL")
PRODUCTS_FILE_PATH = os.getenv("PRODUCTS_FILE_PATH")

def parse_args():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(description="Import products from CSV to database")
    parser.add_argument("--environment", required=True, choices=['internal', 'mainnet'],
                        help="Specify whether this is for internal or mainnet environment")
    parser.add_argument("--csv-path",
                        default=PRODUCTS_FILE_PATH,
                        help="Path to the CSV file containing product data")
    parser.add_argument("--db-uri",
                        default=DATABASE_URL,
                        help="Database URI (e.g., postgresql://user:password@host/database)")

    args = parser.parse_args()

    # Validate required parameters
    if not args.csv_path:
        parser.error("CSV file path is required. Provide with --csv-path or set PRODUCTS_FILE_PATH environment variable")
    if not args.db_uri:
        parser.error("Database URI is required. Provide with --db-uri or set DATABASE_URL environment variable")

    return args

def parse_boolean(value: str) -> bool:
    return value.strip().upper() == "TRUE"

def parse_enum(enum_class, value: str):
    if value:
        try:
            return enum_class[value.strip().upper()]
        except KeyError:
            print(f"âš ï¸ {value} is not a valid {enum_class.__name__}. Using default.")
    return None

def parse_int(value: str):
    return int(value) if value.strip() else None

def parse_float(value: str):
    return float(value) if value.strip() else None

def parse_datetime(value: str):
    try:
        # Parse to datetime then ensure it has UTC timezone
        dt = datetime.fromisoformat(value) if value.strip() else None
        if dt and dt.tzinfo is None:
            # If no timezone info, assume UTC
            dt = dt.replace(tzinfo=timezone.utc)
        return dt
    except ValueError:
        return None

def process_csv_row(row: dict, is_internal: bool) -> dict:
    """CSV í–‰ì„ íŒŒì‹±í•˜ì—¬ Product ëª¨ë¸ì— ë§ëŠ” ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    csv_data = {
        "id": parse_int(row["id"]),
        "name": row["name"],
        "google_sku": row["google_sku"],
        "apple_sku": row["apple_sku"],
        "apple_sku_k": row["apple_sku_k"],
        "daily_limit": parse_int(row["daily_limit"]),
        "weekly_limit": parse_int(row["weekly_limit"]),
        "account_limit": parse_int(row["account_limit"]),
        "order": parse_int(row["order"]),
        "active": parse_boolean(row["active"]),
        "open_timestamp": parse_datetime(row["open_timestamp"]),
        "close_timestamp": parse_datetime(row["close_timestamp"]),
        "discount": parse_float(row["discount"]),
        "rarity": parse_enum(ProductRarity, row["rarity"]),
        "path": "=",
        "l10n_key": "=",
        "size": parse_enum(ProductAssetUISize, row["size"]),
        "bg_path": None,
        "popup_path_key": row["popup_path_key"] if row["popup_path_key"] else None,
        "required_level": parse_int(row["required_level"]),
        "product_type": parse_enum(ProductType, row["product_type"]),
        "mileage": parse_int(row["mileage"]),
        "mileage_price": parse_int(row["mileage_price"])
    }

    # For internal environment, adjust open_timestamp if it's in the future
    current_time_utc = datetime.now(timezone.utc)
    if is_internal and csv_data["open_timestamp"] and csv_data["open_timestamp"] > current_time_utc:
        old_timestamp = csv_data["open_timestamp"]
        csv_data["open_timestamp"] = current_time_utc
        print(f"ğŸ•’ Internal environment detected: Adjusting open_timestamp from {old_timestamp} to {csv_data['open_timestamp']} (UTC)")

    return csv_data

def compare_and_update_product(db: Session, csv_data: dict, is_internal: bool, interactive: bool = True) -> bool:
    """ê¸°ì¡´ DB ë°ì´í„°ì™€ CSV ë°ì´í„°ë¥¼ ë¹„êµ í›„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    existing_product = db.query(Product).filter(Product.id == csv_data["id"]).first()

    if existing_product:
        changes = {}
        for key, value in csv_data.items():
            if getattr(existing_product, key) != value:
                changes[key] = (getattr(existing_product, key), value)

        if changes:
            print(f"\nğŸ” ê¸°ì¡´ Product ID {existing_product.id} ë³€ê²½ ì‚¬í•­ ë°œê²¬:")
            for field, (old, new) in changes.items():
                print(f"  - {field}: ê¸°ì¡´({old}) â†’ ë³€ê²½({new})")

            if not interactive or input("ë³€ê²½ì„ ì ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower() == "y":
                for field, (_, new_value) in changes.items():
                    setattr(existing_product, field, new_value)
                print(f"âœ… Product ID {existing_product.id} ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
                return True
            else:
                print("â© ë³€ê²½ ì‚¬í•­ì´ ì ìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return False
    else:
        new_product = Product(**csv_data)
        db.add(new_product)
        print(f"ğŸ†• ìƒˆë¡œìš´ Product ì¶”ê°€: ID {csv_data['id']}")
        return True

def import_products_from_csv(db: Session, csv_path: str, environment: str, interactive: bool = True) -> tuple[int, int]:
    """
    CSV íŒŒì¼ì—ì„œ ìƒí’ˆ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ë°ì´í„°ë² ì´ìŠ¤ì— ì„í¬íŠ¸í•©ë‹ˆë‹¤.

    Args:
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        csv_path: CSV íŒŒì¼ ê²½ë¡œ
        environment: 'internal' ë˜ëŠ” 'mainnet'
        interactive: ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì„ì§€ ì—¬ë¶€

    Returns:
        tuple[int, int]: (ì²˜ë¦¬ëœ ìƒí’ˆ ìˆ˜, ì—…ë°ì´íŠ¸ëœ ìƒí’ˆ ìˆ˜)
    """
    if environment not in ['internal', 'mainnet']:
        raise ValueError("environment must be either 'internal' or 'mainnet'")

    is_internal = environment == 'internal'
    processed_count = 0
    updated_count = 0

    try:
        with open(csv_path, mode="r", encoding="utf-8") as file:
            reader = csv.DictReader(file)
            for row in reader:
                processed_count += 1
                csv_data = process_csv_row(row, is_internal)
                if compare_and_update_product(db, csv_data, is_internal, interactive):
                    updated_count += 1

            db.commit()
            print(f"\nâœ… CSV ë°ì´í„° ë™ê¸°í™” ì™„ë£Œ! (ì²˜ë¦¬: {processed_count}, ì—…ë°ì´íŠ¸: {updated_count})")
            return processed_count, updated_count

    except Exception as e:
        db.rollback()
        raise e

def import_products(csv_path: str, db_uri: str, environment: str):
    """CLI ë„êµ¬ìš© ì„í¬íŠ¸ í•¨ìˆ˜"""
    print(f"\nğŸŒ Selected environment: {environment.upper()}")
    print(f"â° Current UTC time: {datetime.now(timezone.utc)}")

    if input(f"ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? ì´ ì‘ì—…ì€ {environment.upper()} í™˜ê²½ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. (y/n): ").strip().lower() != "y":
        print("â© ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    engine = create_engine(db_uri)
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    db: Session = SessionLocal()

    try:
        import_products_from_csv(db, csv_path, environment)
    finally:
        db.close()
        print("ğŸ”Œ DB ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    args = parse_args()
    import_products(args.csv_path, args.db_uri, args.environment)
